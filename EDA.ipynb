{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d555f44b",
   "metadata": {},
   "source": [
    "# Prueba tecnica parte 2: Limpieza y análisis exploratorio\n",
    "A continuacion se muestra el proceso realizado para la limpienza y normalización de datos del dataset: `datos mercado inmobiliario`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f60c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias que se van a usar y cargar el DataFrame desde el CSV\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = r\"C:\\Users\\LENOVO\\OneDrive\\src\\Analisis_de_mercado\\datos_prueba_técnica- Data.csv\"\n",
    "## Cambiar ruta por la del bucket\n",
    "df = pd.read_csv(path, encoding='utf-8')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df64a2",
   "metadata": {},
   "source": [
    "## 1. Analisis de celdas duplicadas\n",
    "pandas tiene la función `df.duplicated` que analiza si una fila se encontro anteriormente en el df. Se va a usar esta función analizando 5 columnas que son criticas en la coincidencia de los registros: \n",
    "* id \n",
    "* codigo_web\n",
    "* tipo de inmueble: Este puede estar listado de otra forma edificio o casa \n",
    "* nombre_publicación\n",
    "* last_edited: Esto se realiza con el fin de conservar la versión final de cada registro en caso de estar duplicado. Se realiza un sort para tener el ultimo registro al final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43aeb6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de propiedades duplicadas: 69999\n",
      "propiedades totales: 70001\n"
     ]
    }
   ],
   "source": [
    "# Sort de las filas para tener el ultimo update abajo siempre\n",
    "df = df.sort_values('last_edited', ascending=True)\n",
    "mask = df.duplicated(subset=([\"id\",\"codigo_web\",\"tipo_inmueble\",\"nombre_publicacion\",\"last_edited\"]))\n",
    "# Print para contar el numero de propiedades que tienen un registro duplicado, cuenta los TRUE del mask\n",
    "print(f\"Cantidad de propiedades duplicadas: {mask.sum()}\") \n",
    "# Eliminar columnas duplicadas\n",
    "df = df.drop_duplicates(subset=[\"id\",\"codigo_web\",\"tipo_inmueble\",\"nombre_publicacion\",\"last_edited\"])\n",
    "print(f\"propiedades totales: {df[\"id\"].count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca7f3a4",
   "metadata": {},
   "source": [
    "## 2. Normalizado de columnas de TEXTO \n",
    "### Revisar que columnas necesitan ser normalizadas\n",
    "para determinar cuales columnas tienen texto con formatos diferentes, se realiza un analisis preliminar empleando la función `set()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c258676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bogota', 'bogotá D.C', 'BOGOTÁ', 'bogotá dc.', 'bogota d.c.', 'Bogotá', 'Bogota DC'}\n",
      "{'Metro Cuadrado', 'CienCuadras', 'Habi', 'Fincaraiz', 'MercadoLibre'}\n",
      "{'Apartamento', 'APARTAMENTO', 'Casa'}\n",
      "{'FOR_SALE'}\n",
      "{'Cundinamarca', 'CUNDINAMARCA'}\n",
      "['Antonio Nariño', 'Barrios Unidos', 'Bosa', 'Chapinero', 'Ciudad Bolivar', 'Engativá', 'Fontibón', 'Kennedy', 'La Candelaria', 'Los Mártires', 'Puente Aranda', 'Rafael Uribe', 'San Cristóbal', 'Santa Fé', 'Suba', 'Sumapaz', 'Teusaquillo', 'Tunjuelito', 'Usaquén', 'Usme']\n"
     ]
    }
   ],
   "source": [
    "ciudad = set(df[\"ciudad\"]) \n",
    "portal_inm = set(df[\"portal_inmobiliario\"]) \n",
    "tipo_inmueble = set(df[\"tipo_inmueble\"]) \n",
    "tipo_negocio = set(df[\"tipo_negocio\"]) \n",
    "departamento = set(df[\"departamento\"])\n",
    "subzona = sorted(set(df[\"subzona\"]))\n",
    "\n",
    "print(f\"{ciudad}\\n{portal_inm}\\n{tipo_inmueble}\\n{tipo_negocio}\\n{departamento}\\n{subzona}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99658bde",
   "metadata": {},
   "source": [
    "la columna `ciudad, tipo_inmueble, departamento` tienen inconsistencias de formato, `portal_inmobiliario, subzona` no tienen entonces solo se va a trabajar con las primeras 3. \n",
    "### Ciudad\n",
    "Para la columna `[ciudad]` se va a eliminar los espacios, se va a dejar en mayusculas y eliminar los acentos y la palabra \"DC\" solo conservando **\"BOGOTA\"** \n",
    "### tipo de inmueble & departamento\n",
    "Para estos, como no hay acentos ni condiciones especiales, solo se van a dejar en mayusculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf130827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BOGOTA'}\n",
      "{'CASA', 'APARTAMENTO'}\n",
      "{'CUNDINAMARCA'}\n"
     ]
    }
   ],
   "source": [
    "df['ciudad'] = df['ciudad'].str.upper().str.strip()\n",
    "patron_ciudad = r\"^(?=.*[AÁÉÍÓÚÜÑ]|\\bD\\.?C\\.?\\b).*$\"\n",
    "df['ciudad'] = df['ciudad'].str.replace(\n",
    "    patron_ciudad,\n",
    "    'BOGOTA',\n",
    "    regex=True\n",
    ")\n",
    "df[\"tipo_inmueble\"] = df[\"tipo_inmueble\"].str.upper()\n",
    "df[\"departamento\"] = df[\"departamento\"].str.upper()\n",
    "\n",
    "# Se realiza de nuevo un check para comprobar que haya funcionado\n",
    "ciudad = set(df[\"ciudad\"]) \n",
    "tipo_inmueble = set(df[\"tipo_inmueble\"]) \n",
    "departamento = set(df[\"departamento\"]) \n",
    "\n",
    "print(f\"{ciudad}\\n{tipo_inmueble}\\n{departamento}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5d363",
   "metadata": {},
   "source": [
    "## 3. Normalizado de columnas de FECHA \n",
    "Ahora se cambia el formato de las columnas que tienen tipo date(), para esto se usa la función `to_datetime()` que segun el contenido de texto se ajusta a un formato `%Y-%m-%d` o `%Y-%m-%d %H:%M:%S.%f'` o se autodetecta, para las columnas `\"fecha_insercion_third_party\",'fecha_publicacion', 'last_edited'` se realiza una funcion lambda y para `'fecha_insercion_interna'` se usa solo la funcion normal `to_datetime()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\"fecha_insercion_third_party\",'fecha_publicacion', 'last_edited']\n",
    "df[dates] = df[dates].apply(lambda col: pd.to_datetime(col, format='%Y-%m-%d', errors='coerce'))\n",
    "df['fecha_insercion_interna'] = pd.to_datetime(df['fecha_insercion_interna'],format='%Y-%m-%d %H:%M:%S.%f',errors='coerce')\n",
    "\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276cc5e5",
   "metadata": {},
   "source": [
    "## 4. Limpieza de datos atipicos \n",
    "Primero se debe realizar una analisis sobre el conjunto de datos para estimar que datos no tienen sentido fisico, con eso se acotan los resultados y posteriormente eliminar los outliers o valores \"atipicos\". Esto se realiza con la función `.describe().T`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ba343",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape[0]) # Tamaño de la matriz antes de la limpieza\n",
    "# Se realiza el analisis sobre las columnas que tiene valores numericos sobre los cuales se puedan estimar limites \"razonables\"\n",
    "col_numericas = ['latitud', 'longitud','area', 'area_total','habitaciones', 'banios', 'parqueaderos', 'precio_venta', 'precio_usd',\n",
    "       'estrato', 'precio_admon','precio_admon_incluido', 'anhio_construccion', 'pisos_edificio', 'piso', 'ascensor',]\n",
    "print(df[col_numericas].describe().T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfbbf45",
   "metadata": {},
   "source": [
    "## 4.1. Valores sin sentido fisico\n",
    "Al analizar el resultado de `.describe()` se pueden concluir las siguientes cosas: \n",
    "* Latitud y longitud estan fuera de los rangos para la ciudad de bogota\n",
    "* Los precios de venta tienen valores muy pequeños - pero pueden ser no irreales\n",
    "* El año de construcción esta mal listado el minimo no puede ser 2\n",
    "* Los estratos en bogotá van de 1 a 6 \n",
    "* El edificio mas alto en bogota tiene 67 pisos y es el bacata\n",
    "\n",
    "Con esto se establecen los limites reales de algunas columnas y se realizan un filtrado del df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e2f7861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementos filtrados: 52087\n",
      "                      count          mean           std           min  \\\n",
      "latitud             17914.0  4.681592e+00  5.011399e-02  4.451515e+00   \n",
      "longitud            17914.0 -7.408048e+01  4.378083e-02 -7.421353e+01   \n",
      "area                17914.0  1.515140e+02  1.986082e+03  3.000000e+00   \n",
      "area_total            313.0  4.586559e+02  6.592879e+02  1.800000e+01   \n",
      "habitaciones        17914.0  3.008987e+00  1.448873e+00  1.000000e+00   \n",
      "banios              17914.0  2.587027e+00  1.278476e+00  1.000000e+00   \n",
      "parqueaderos        17914.0  1.342860e+00  1.194064e+00  0.000000e+00   \n",
      "precio_venta        17914.0  1.870522e+09  5.927013e+10  1.150000e+06   \n",
      "precio_usd          17913.0  4.559961e+05  1.446060e+07  2.766200e+02   \n",
      "estrato             17914.0  4.138718e+00  1.346021e+00  1.000000e+00   \n",
      "precio_admon        13460.0  4.397840e+06  7.073517e+07  1.000000e+00   \n",
      "anhio_construccion  17914.0  2.006900e+03  9.625897e+00  1.937000e+03   \n",
      "pisos_edificio        554.0  5.319495e+00  5.360503e+00  1.000000e+00   \n",
      "piso                17914.0  4.732500e+00  4.723447e+00  1.000000e+00   \n",
      "ascensor              726.0  1.378788e+00  7.074318e-01  1.000000e+00   \n",
      "\n",
      "                             25%           50%           75%           max  \n",
      "latitud             4.649369e+00  4.688082e+00  4.718829e+00  4.824205e+00  \n",
      "longitud           -7.411076e+01 -7.406410e+01 -7.404725e+01 -7.401500e+01  \n",
      "area                5.701250e+01  8.904000e+01  1.642225e+02  2.047430e+05  \n",
      "area_total          1.540000e+02  2.570000e+02  5.500000e+02  9.158000e+03  \n",
      "habitaciones        2.000000e+00  3.000000e+00  3.000000e+00  2.200000e+01  \n",
      "banios              2.000000e+00  2.000000e+00  3.000000e+00  1.500000e+01  \n",
      "parqueaderos        0.000000e+00  1.000000e+00  2.000000e+00  1.500000e+01  \n",
      "precio_venta        2.800000e+08  5.000000e+08  9.000000e+08  6.400000e+12  \n",
      "precio_usd          6.871166e+04  1.220375e+05  2.196676e+05  1.562080e+09  \n",
      "estrato             3.000000e+00  4.000000e+00  5.000000e+00  6.000000e+00  \n",
      "precio_admon        1.800000e+05  4.110000e+05  8.437000e+05  3.366000e+09  \n",
      "anhio_construccion  2.002000e+03  2.005000e+03  2.014000e+03  2.024000e+03  \n",
      "pisos_edificio      3.000000e+00  3.000000e+00  5.000000e+00  4.000000e+01  \n",
      "piso                2.000000e+00  3.000000e+00  6.000000e+00  6.700000e+01  \n",
      "ascensor            1.000000e+00  1.000000e+00  2.000000e+00  5.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "latitud_bogota = [4.4,4.86] #lb, ub\n",
    "longitud_bogota = [-76.63542,-73.97] #lb,ub\n",
    "anhio_edificacion = [1580,2025] #año donde se fundo el Palacio de San Carlos\n",
    "estratos = [1,6] #lb, ub\n",
    "pisos_max = 67.0\n",
    "\n",
    "mask = (\n",
    "    (df['latitud'] >= latitud_bogota[0]) & (df['latitud'] <= latitud_bogota[1]) &\n",
    "    (df['longitud'] >= longitud_bogota[0]) & (df['longitud'] <= longitud_bogota[1]) &\n",
    "    (df['anhio_construccion'] >= anhio_edificacion[0]) & (df['anhio_construccion'] <= anhio_edificacion[1]) &\n",
    "    (df['estrato'] >= estratos[0]) & (df['estrato'] <= estratos[1]) &\n",
    "    (df[\"piso\"]<= pisos_max)\n",
    ")\n",
    "# Aplicar la máscara al DataFrame\n",
    "df_filtrado = df[mask]\n",
    "print(f\"Elementos filtrados: {df.shape[0]-df_filtrado.shape[0]}\")\n",
    "# Se hace print de la descripcion del nuevo df.\n",
    "print(df_filtrado[col_numericas].describe().T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a2771",
   "metadata": {},
   "source": [
    "## 4.2. analisis de outliers \n",
    "Ahora se realiza un analisis outliers empleando el metodo de Tukey de percentiles y se va a realizar sobre las columnas `\"precio_venta\", \"area\",'precio_admon'` las cuales son datos relevantes y que se pueden modelar sin tener necesariamente \"valores irreales\".\n",
    "1. Se realiza una vizualización prerliminar de los datos por dos medios. Primero un histograma y segundo un diagrama de cajas y bigotes\n",
    "2. Se realiza el metodo de cuartiles para eliminar filtrar los outliers \n",
    "3. Se realiza la comparacion de los datos obtenidos finalmente\n",
    "\n",
    "El analisis se realiza sobre el nuevo dataframe filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d02f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_visual = ['latitud', 'longitud','area', 'area_total','habitaciones', 'banios', 'parqueaderos', 'precio_venta', 'precio_usd',\n",
    "       'estrato', 'precio_admon','precio_admon_incluido', 'anhio_construccion', 'pisos_edificio', 'piso', 'ascensor']\n",
    "col_estadisticos = [\"precio_venta\", \"area\",'precio_admon']\n",
    "\n",
    "df_filtrado[col_visual].hist(bins=50, figsize=(16,12))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado[col_estadisticos].plot(kind=\"box\",figsize=(16,12))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad0c8e",
   "metadata": {},
   "source": [
    "Se crea la función `eliminar_atipicos` que recibe como argumentos el df y las columnas sobre las cuales se va a realizar el analisis de outliers. Para el analisis de Tukey se calcular el _Q1_ y _Q3_ y con ellos el _IQR_ que es:\n",
    "```\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "donde se tienen que estimar los limites inferiores o superiores (bigotes)\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5757e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_atipicos(df,columnas=col_estadisticos):\n",
    "   # Se hace un if en caso de que no se entregue el argumento columnas\n",
    "   if columnas is None:\n",
    "       columnas = df.select_dtypes(include=[\"number\"]).columns\n",
    "   \n",
    "   # Se crea una copia del df sobre el que se va a trabajar\n",
    "   df_sin_atipicos = df.copy()\n",
    "   \n",
    "   for column in columnas:\n",
    "       Q1 = df[column].quantile(0.25)\n",
    "       Q3 = df[column].quantile(0.75)\n",
    "       IQR = Q3 - Q1\n",
    "       lower_b = Q1 - 1.5*IQR\n",
    "       upper_b = Q3 + 1.5*IQR\n",
    "       df_sin_atipicos = df_sin_atipicos[(df_sin_atipicos[column]>= lower_b) & (df_sin_atipicos[column]<= upper_b)]\n",
    "   return df_sin_atipicos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be6e9c",
   "metadata": {},
   "source": [
    "Se aplica la funcion sobre el dataframe\n",
    "Se analiza la opcion de aplicar la función por separado. \n",
    "\n",
    "1. Se realiza el analisis de outliers sobre todas las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aef5d3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antes 17914\n",
      "despues 12183\n",
      "Elementos filtrados: 5731\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    df_filtro_completo =eliminar_atipicos(df_filtrado,columnas=col_estadisticos)\n",
    "print(\"antes\",df_filtrado.shape[0])\n",
    "print(\"despues\",df_filtro_completo.shape[0])\n",
    "print(f\"Elementos filtrados: {df_filtrado.shape[0]-df_filtro_completo.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea0d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtro_completo.plot(kind=\"box\",figsize=(16,12))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtro_completo.hist(bins=50, figsize=(10,10))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa176f",
   "metadata": {},
   "source": [
    "Ahora se analiza el caso donde se realizan por separado la aplicación del analisis de outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e28f9280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antes 17914\n",
      "despues 11265\n",
      "Elementos filtrados: 6649\n"
     ]
    }
   ],
   "source": [
    "# Analisis sobre \"area\" y \"precio_admon\"\n",
    "for i in range(3):\n",
    "    new_df =eliminar_atipicos(df_filtrado,columnas=col_estadisticos[1:3])\n",
    "# Analissi sobre el \"precio_venta\"\n",
    "for i in range(3):\n",
    "    new_df =eliminar_atipicos(new_df,columnas=col_estadisticos[0:1])\n",
    "print(\"antes\",df_filtrado.shape[0])\n",
    "print(\"despues\",new_df.shape[0])\n",
    "print(f\"Elementos filtrados: {df_filtrado.shape[0]-new_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba83e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.plot(kind=\"box\",figsize=(16,12))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81710ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.hist(bins=50, figsize=(10,10))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea32f542",
   "metadata": {},
   "source": [
    "## 5. Analisis de datos filtrados\n",
    "Despues de observar los datos filtrados se obtuvieron las siguientes conclusiones \n",
    "1. Se partio con un total de 140.000 registros de los cuales **69999** son registros duplicados. Aproximadamente el **50%**. \n",
    "2. De los 70001 registros restantes se realizo un analisis sobre los maximos y minimos para encontrar anomalias. Se evidenciaron en las columnas de longitud, latitud, año de construcción, estratos y numero de piso. Sobre estos se ajustaron los valores de acuerdo a datos reales y que no son inconsistentes y se elimino un total de **52087** registros. Estos pueden tener uno o mas inputs que pueden ser producto de \"error\" humano sin embargo para el posterior analisis se descartan. Se elimino cualquier registros que no estuviera al menos en uno de los rangos permitidos. El total de registros despues de esto fue de **17914**\n",
    "3. Se realizo un analisis de outliers para determinar valores \"atipicos\" en variables que pueden llegar a tener sentido fisico como un area o precio de venta elevados pero que pueden ser considerados excepcionales. Se empleo el metodo de cuartiles de Tukey para esto, y ocon ello se pudo filtrar un total de **6649** registros. \n",
    "\n",
    "Con esto se eliminaron al final **128.735** registros que representan el **91,95%** de los registros iniciales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d320ef1",
   "metadata": {},
   "source": [
    "# Prueba tecnica parte 3: Análisis de datos\n",
    "Para esta sección se quiere determinar si el precio de un inmueble varia según el piso en el que se encuentre. Para esto solo se van a contrastar dos variables **Precio de venta** y **piso**. Sin embargo, en necesario contemplar otras variables de forma no directa como es el estrato, area ya que estas influyen en gran medida sobre el precio. Para contemplar su impacto se va a realizar un analisis segmentado tomando por estrato y por cuartiles sobre el rango de areas y así tener grupos mas homogeneos. \n",
    "1. Se crea un nuevo DataFrame para el analisis\n",
    "2. se eliminan celdas nulas\n",
    "3. Se realiza la segmentación de las variables que no participan en la regreción\n",
    "4. Se realiza una regrecion por cada combinacion de segmentos de variable definidos anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6eec5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Selección de columnas para analisis estadistico y limpieza\n",
    "df_model = new_df[['precio_venta', 'piso', 'area', 'habitaciones', 'estrato']].copy()\n",
    "df_model.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_model.dropna(subset=['precio_venta', 'piso', 'area', 'habitaciones', 'estrato'], inplace=True)\n",
    "\n",
    "# Segmentación de variables que no participan en la regreción\n",
    "# Área en 4 cuantiles\n",
    "df_model['area_seg'] = pd.qcut(\n",
    "    df_model['area'], q=4, labels=['Q1','Q2','Q3','Q4']\n",
    ")\n",
    "\n",
    "# Estrato discretizado 1 a 6, intervalos (0.5,1.5], (1.5,2.5], ..., (5.5,6.5]\n",
    "bins_estrato = np.arange(0.5, 7, 1)\n",
    "labels_estrato = [1, 2, 3, 4, 5, 6]\n",
    "df_model['estrato_seg'] = pd.cut(\n",
    "    df_model['estrato'],\n",
    "    bins=bins_estrato,\n",
    "    labels=labels_estrato,\n",
    "    right=True,\n",
    "    include_lowest=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69792e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   area_seg  estrato_seg     coef_piso     pval_piso        r2  n_obs\n",
      "0        Q1            2  2.417730e+06  7.648089e-16  0.084641    737\n",
      "1        Q1            3  8.758614e+05  5.664901e-06  0.014896   1375\n",
      "2        Q1            4 -3.607760e+05  4.282588e-01  0.001284    491\n",
      "3        Q2            2  1.159411e+06  2.124149e-02  0.017110    310\n",
      "4        Q2            3  1.261567e+06  9.024326e-05  0.012574   1214\n",
      "5        Q2            4  2.408028e+06  2.677815e-06  0.024687    884\n",
      "6        Q2            5  6.988555e+06  5.125543e-04  0.044278    269\n",
      "7        Q2            6  2.897806e+06  1.168249e-01  0.010752    230\n",
      "8        Q3            3  6.389254e+06  3.808924e-10  0.095529    393\n",
      "9        Q3            4  7.093997e+06  6.412648e-26  0.079020   1349\n",
      "10       Q3            5  1.555737e+07  3.118673e-11  0.088932    476\n",
      "11       Q3            6  1.507429e+07  7.161817e-05  0.033517    465\n",
      "12       Q4            3  7.860079e+06  9.676875e-02  0.023005    121\n",
      "13       Q4            4  6.619656e+06  3.086497e-04  0.021622    598\n",
      "14       Q4            5  1.172414e+07  9.353338e-10  0.040216    915\n",
      "15       Q4            6  6.240452e+06  3.033073e-03  0.007709   1138\n"
     ]
    }
   ],
   "source": [
    "## Regreciones\n",
    "\n",
    "results = []\n",
    "#group_cols = ['area_seg', 'hab_seg', 'estrato_seg']\n",
    "group_cols = ['area_seg', 'estrato_seg']\n",
    "\n",
    "for keys, group in df_model.groupby(group_cols,observed=True):\n",
    "    if len(group) < 100: #Se toman los grupos con mas de 100 propiedades para considerarlos significativo\n",
    "        continue\n",
    "    X = sm.add_constant(group['piso'])\n",
    "    y = group['precio_venta']\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    results.append({\n",
    "        **dict(zip(group_cols, keys)),\n",
    "        'coef_piso': model.params['piso'],\n",
    "        'pval_piso': model.pvalues['piso'],\n",
    "        'r2':        model.rsquared,\n",
    "        'n_obs':     len(group)\n",
    "    })\n",
    "\n",
    "# 4. Resumen de resultados\n",
    "summary = pd.DataFrame(results)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8a6c24",
   "metadata": {},
   "source": [
    "## Analisis final\n",
    "H_0 : El numero de piso **no** tiene efecto en el precio de venta\n",
    "\n",
    "### Segmentos significativos (p-val < 0.05)\n",
    "Se obtuvo que: Q1 (2,3), Q2 (2,3,4,5), Q3 (3,4,5,6), Q4 (4,5,6) Tuvieron valores significativos, hay una tendencia que indica que entre mayor sea el Q* (mas area) tiene a ser mas relevante a medida que se aumenta los estratos y los coeficientes aumentan a medida que se aumenta el estrato ya que el precio por apartamento es mayor. Todos presentan pendientes positivas lo cual el precio por apartamento aumenta a medida que aumenta el piso en el que se encuentra mostrando una relacion directamente proporcional \n",
    "\n",
    "### Segmentos no significativos (p-val >= 0.05)\n",
    "solo 3 grupos tienen un p-val mayor al 5% Q1(4), Q2(6), Q4(3) con solo el primer caso con un coeficiente negativo\n",
    "\n",
    "### R^2 \n",
    "En la  tabla global, se tiene que el `R^2` mas alto es de 0.0955 lo cual es menor a 2. Esto indica que el piso no es un factor significativo al momento de estimar el precio de un inmueble, hay factores que pueden llegar a ser relevantes o el conjunto de estos. \n",
    "\n",
    "### Conclución \n",
    "Se puede asegurar en la mayoria de los casos estudiados con un 95% de seguridad que el piso en el que se encuenrtre un inmueble afecta el precio de venta de este. Sin embargo, este parece no ser el factor fundamental por el cual el precio fluctue, puede haber otros aspectos mas relevantes a analizar como el estrato, nivel de construcción, año de construcción, entre otros.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6f5599",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f96c3994",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
